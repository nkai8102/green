{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2ef3d0-c8bc-4511-934e-7205c5825dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "train = pl.read_csv(\"data/train.csv\").rename({\"\": \"idx\"})\n",
    "test = pl.read_csv(\"data/test.csv\").rename({\"\": \"idx\"})\n",
    "sample_submission = pl.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8f61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = \"feat00\" # for catboost\n",
    "\n",
    "# train, testを結合\n",
    "train_test = pl.concat([train.drop(\"health\"), test])\n",
    "\n",
    "# problemに対するfeature engineering\n",
    "problem_lst = [\"WiresRope\", \"Stones\", \"MetalGrates\", \"RootOther\", \"TrunkOther\", \n",
    "               \"BranchLights\", \"TrunkLights\", \"BranchOther\", \"Sneakers\"]\n",
    "for prob in problem_lst:\n",
    "    train_test = train_test.with_columns(pl.when(pl.col(\"problems\").str.contains(prob)).then(1).otherwise(0).alias(f\"problems_contain_{prob}\"))\n",
    "train_test = train_test.drop(\"problems\")\n",
    "\n",
    "# ordinal encoding\n",
    "cols_notcat = ['idx', 'created_at', 'tree_dbh']\n",
    "cols_cat = [c for c in train_test.columns if not c in cols_notcat] # カテゴリ特徴量\n",
    "for col in cols_cat:\n",
    "    if \"problems_contain_\" in col: # 0/1フラグ特徴量はordinal encodingの対象外\n",
    "        continue\n",
    "    train_test = train_test.with_columns(pl.col(col).cast(pl.Utf8)) # integerの場合はstringに変換\n",
    "    train_test = train_test.with_columns(pl.col(col).cast(pl.Categorical).cast(pl.UInt32))\n",
    "\n",
    "# 多重共線性を排除\n",
    "cols_drop = [\"spc_common\", \"nta_name\", \"borocode\"]\n",
    "cols_cat = [c for c in cols_cat if not c in cols_drop]\n",
    "train_test = train_test.drop(cols_drop)\n",
    "\n",
    "# \"created_at\"特徴量を、最も古い日付(15/5/19)からの経過日数に変換\n",
    "dates = train_test[\"created_at\"].str.to_datetime()\n",
    "dates = pl.Series((dates - dates.min()).dt.total_days())\n",
    "train_test = train_test.with_columns(dates.alias(\"created_at\"))\n",
    "\n",
    "# split train/test\n",
    "n_train = len(train)\n",
    "\n",
    "# train feature for multiclass clf\n",
    "train_feat = train_test.filter(pl.col(\"idx\") < n_train)\n",
    "train_feat = train_feat.join(train.select([\"idx\", \"health\"]), on=\"idx\", how=\"left\")\n",
    "train_feat.write_csv(f\"feat/feat_train_{feat}.csv\")\n",
    "\n",
    "# test feature\n",
    "test_feat = train_test.filter(pl.col(\"idx\") >= n_train)\n",
    "test_feat.write_csv(f\"feat/feat_test_{feat}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b9f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_encoder import TargetEncoder\n",
    "\n",
    "feat = \"feat01\" # for lightGBM\n",
    "\n",
    "# target encodingにむけて2クラス分類用ラベル作成\n",
    "train = train.with_columns([pl.when(pl.col(\"health\") == h).then(1).otherwise(0).alias(f\"health_is_{h}\") \n",
    "                            for h in range(3)])\n",
    "\n",
    "# target encodingを適用\n",
    "cat_df_train = train_feat[cols_cat]\n",
    "cat_df_test = test_feat[cols_cat]\n",
    "\n",
    "for health in range(3): # 3クラス分類のため、それぞれのターゲットクラスに基づいてencodingする\n",
    "    encoder = TargetEncoder()\n",
    "    tenc_df_train = encoder.fit_transform(cat_df_train, train[f\"health_is_{health}\"])\n",
    "    tenc_df_test = encoder.transform(cat_df_test)\n",
    "\n",
    "    train_feat = pl.concat([train_feat, tenc_df_train], how=\"horizontal\")\n",
    "    test_feat = pl.concat([test_feat, tenc_df_test], how=\"horizontal\")\n",
    "\n",
    "# save    \n",
    "train_feat.write_csv(f\"feat/feat_train_{feat}.csv\")\n",
    "test_feat.write_csv(f\"feat/feat_test_{feat}.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad340d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = \"feat02\" # for RandomForest\n",
    "\n",
    "# trainにおける、各クラスのデータ件数率\n",
    "weights_train = np.array(train[\"health\"].value_counts().sort(\"health\")[\"count\"]) / len(train)\n",
    "\n",
    "# ターゲットエンコーディングの特徴量の欠損を、trainにおけるデータ件数率で埋める\n",
    "for h in range(3):\n",
    "    cols = [c for c in train_feat.columns if f\"health_is_{h}\" in c]\n",
    "    train_feat = train_feat.with_columns(train_feat[cols].fill_nan(weights_train[h]))\n",
    "    test_feat = test_feat.with_columns(test_feat[cols].fill_nan(weights_train[h]))\n",
    "    \n",
    "# カテゴリ特徴量の欠損を-1で埋める（カテゴリ特徴量の欠損を受け付けない）\n",
    "train_feat = train_feat.with_columns(train_feat[cols_cat].fill_null(-1))\n",
    "test_feat = test_feat.with_columns(test_feat[cols_cat].fill_null(-1))\n",
    "\n",
    "# save    \n",
    "train_feat.write_csv(f\"feat/feat_train_{feat}.csv\")\n",
    "test_feat.write_csv(f\"feat/feat_test_{feat}.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b90edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = \"feat03\" # for LogisticRegression, NN\n",
    "\n",
    "# Ordinal Encodingの特徴量を削除\n",
    "train_feat = train_feat.drop(cols_cat)\n",
    "test_feat = test_feat.drop(cols_cat)\n",
    "\n",
    "# save    \n",
    "train_feat.write_csv(f\"feat/feat_train_{feat}.csv\")\n",
    "test_feat.write_csv(f\"feat/feat_test_{feat}.csv\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
