{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2ef3d0-c8bc-4511-934e-7205c5825dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from optuna import integration, logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca09f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = \"feat01\"\n",
    "train = pl.read_csv(f\"feat/feat_train_{feat}.csv\")\n",
    "test = pl.read_csv(f\"feat/feat_test_{feat}.csv\")\n",
    "train_origin = pl.read_csv(\"data/train.csv\").rename({\"\": \"idx\"})\n",
    "\n",
    "# cols_exp = [c for c in test.columns if c != \"idx\"]\n",
    "cols_exp = [c for c in test.columns if \"health_is_\" in c] # 線形モデル使用のため、ターゲットエンコーディングの特徴量のみ残す\n",
    "\n",
    "# trainにおける、各クラスのデータ件数率\n",
    "weights_train = np.array(train_origin[\"health\"].value_counts().sort(\"health\")[\"count\"]) / len(train_origin)\n",
    "\n",
    "# カテゴリ特徴量のカラム\n",
    "# cols_cat_int = [\"boro_ct\", \"cb_num\"] # integerだがカテゴリ特徴量とみなすもの\n",
    "# cols_cat = [c for c in train_origin.select(pl.col(pl.Utf8)).columns if c != \"created_at\"] + cols_cat_int # カテゴリ特徴量\n",
    "\n",
    "# # カテゴリ特徴量の欠損を-1で埋める（カテゴリ特徴量の欠損を受け付けない）\n",
    "# train = train.with_columns(train[cols_cat].fill_null(-1))\n",
    "# test = test.with_columns(test[cols_cat].fill_null(-1))\n",
    "\n",
    "# ターゲットエンコーディングの特徴量の欠損を、trainにおけるデータ件数率で埋める\n",
    "for h in range(3):\n",
    "    cols = [c for c in train.columns if f\"health_is_{h}\" in c]\n",
    "    train = train.with_columns(train[cols].fill_nan(weights_train[h]))\n",
    "    test = test.with_columns(test[cols].fill_nan(weights_train[h]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990efad",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(train, cols_exp, col_target, params=None):\n",
    "    \n",
    "    if params is None:\n",
    "        params = {}\n",
    "        \n",
    "    params_add = {}\n",
    "    params |= params_add\n",
    "\n",
    "    x = train[cols_exp].to_numpy()\n",
    "    y = train[col_target].to_numpy()\n",
    "    \n",
    "    # K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    y_valid_pred_lst = []\n",
    "    idx_valid_lst = []\n",
    "    clf_lst = []\n",
    "\n",
    "    # cross validation\n",
    "    for fold, (idx_train, idx_valid) in enumerate(kf.split(x)):\n",
    "        print(\"fold\", fold)\n",
    "        x_train = x[idx_train, :]\n",
    "        x_valid = x[idx_valid, :]\n",
    "        y_train = y[idx_train]\n",
    "        y_valid = y[idx_valid]\n",
    "        \n",
    "        # normalization\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_valid = scaler.transform(x_valid)\n",
    "\n",
    "        # modeling\n",
    "        clf = LogisticRegression(random_state=0, max_iter=1000).fit(x_train, y_train)\n",
    "\n",
    "        # oof\n",
    "        y_valid_pred = clf.predict_proba(x_valid)\n",
    "        y_valid_pred_lst.append(y_valid_pred)\n",
    "        idx_valid_lst.append(idx_valid)\n",
    "        clf_lst.append(clf)\n",
    "\n",
    "    idx_valid = np.hstack(idx_valid_lst)\n",
    "    # y_valid_pred = np.hstack(y_valid_pred_lst)\n",
    "    y_valid_pred = np.vstack(y_valid_pred_lst)\n",
    "    oof_pred = y_valid_pred[np.argsort(idx_valid)]\n",
    "\n",
    "    return clf_lst, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960ae40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(x_test, clf_lst):\n",
    "    y_test_pred_lst = []\n",
    "\n",
    "    for clf in clf_lst:\n",
    "        y_test_pred = clf.predict_proba(x_test)\n",
    "        y_test_pred_lst.append(y_test_pred)\n",
    "\n",
    "    y_test_pred = np.mean(y_test_pred_lst, axis=0)\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4adc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_target = health --------------------------------------------------\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_target = \"health\"\n",
    "print(\"col_target =\", col_target, \"-\"*50)\n",
    "\n",
    "# train logistic regression\n",
    "clf_lst, oof_pred = train_logistic_regression(train, cols_exp, col_target)\n",
    "\n",
    "# normalization for test\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[cols_exp].to_numpy())\n",
    "x_test = scaler.transform(test[cols_exp].to_numpy())\n",
    "\n",
    "# predict test with CV ensemble\n",
    "y_test_pred = predict_test(x_test, clf_lst)\n",
    "\n",
    "# record\n",
    "oof_pred_df = pl.DataFrame(oof_pred, schema=[f\"health_is_{h}\" for h in range(3)])\n",
    "test_pred_df = pl.DataFrame(y_test_pred, schema=[f\"health_is_{h}\" for h in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1f771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "oof_pred_df.write_csv(f\"pred/oof_pred_logisticregression_{feat}.csv\")\n",
    "test_pred_df.write_csv(f\"pred/test_pred_logisticregression_{feat}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d00ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3ba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
